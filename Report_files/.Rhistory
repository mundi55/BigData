if(nrow(invalid_cases) > 0) {
print(invalid_cases)
} else {
cat("Validation passed: W is always 1 when dispovp > 0.\n")
}
selected_vars <- c("immobil")
# Selectie van de variabelen uit de gejoinede dataset
filtered_data <- merged_data %>% select(all_of(selected_vars))
# Bekijk de algemene samenvatting van de geselecteerde variabelen
#skim(filtered_data)
# Distributie van elke variabele + aantal ontbrekende waarden visualiseren
for (var in selected_vars) {
print(ggplot(filtered_data, aes_string(x = var)) +
geom_bar(na.rm = TRUE, fill = "steelblue") +
ggtitle(paste("Distributie van", var)) +
theme_minimal())
# Aantal missende waarden tonen
missing_count <- sum(is.na(filtered_data[[var]]))
total_count <- nrow(filtered_data)
cat(paste("Variabele:", var, "\nOntbrekende waarden:", missing_count,
"\nPercentage ontbrekend:", round((missing_count / total_count) * 100, 2), "%\n\n"))
}
# Combineer alle mutaties in één blok
merged_data <- merged_data %>%
mutate(
# Vervang NA door 0
PBM_STAT = replace_na(PBM_STAT, 0),
STAT_TRAV = replace_na(STAT_TRAV, 0),
# Zet de geselecteerde variabelen om naar factor (categorisch)
TYPE_HAB = as.factor(TYPE_HAB),
zoneres.x = as.factor(zoneres.x),
OCCU1 = as.factor(OCCU1),
travdom = as.factor(travdom),
nb_pers = as.factor(nb_pers),
# Creëer de binaire variabele 'parking_diff'
parking_diff = ifelse(PBM_STAT == 1 | STAT_TRAV == 1, 1, 0)
) %>%
select(-PBM_STAT, -STAT_TRAV)  # Verwijder PBM_STAT en STAT_TRAV
# Voeg de aangepaste variabelen toe aan allgreI_filtered via left_join
allgreI_filtered <- allgreI_filtered %>%
left_join(merged_data %>% select(id_pers, TYPE_HAB, zoneres.x, OCCU1, travdom, nb_pers, parking_diff),
by = "id_pers")
# Controleer of de variabelen correct zijn toegevoegd
str(allgreI_filtered)
# Opslaan van de geüpdatete dataset
save(allgreI_filtered, file = "allgreI_with_new_vars.RData")
# Bekijk een overzicht van de eerste paar rijen
head(allgreI_filtered)
library(dplyr)
# 1. Vind alle kolommen die eindigen op .x of .y
suffix_columns <- names(allgreI_filtered)[grepl("\\.x$|\\.y$", names(allgreI_filtered))]
# 2. Loop door alle suffix kolommen en verwerk ze
for (col in suffix_columns) {
# Haal de originele kolomnaam zonder suffix
base_col <- gsub("\\.x$|\\.y$", "", col)
# Controleer of de kolom zonder suffix al bestaat
if (base_col %in% names(allgreI_filtered)) {
# Vergelijk de kolommen
if (identical(allgreI_filtered[[col]], allgreI_filtered[[base_col]])) {
# Als ze identiek zijn, verwijder de .x/.y kolom
allgreI_filtered <- allgreI_filtered %>%
select(-all_of(col))
cat("", col, "is identiek aan", base_col, "en is verwijderd.\n")
} else {
cat("️", col, "verschilt van", base_col, ". Handmatige controle vereist.\n")
}
} else {
# Als de basisversie niet bestaat, hernoem de kolom zonder suffix
allgreI_filtered <- allgreI_filtered %>%
rename(!!base_col := all_of(col))
cat("", col, "is hernoemd naar", base_col, ".\n")
}
}
# 3. Verwijder PBM_STAT en STAT_TRAV als ze nog bestaan
allgreI_filtered <- allgreI_filtered %>%
select(-any_of(c("PBM_STAT", "STAT_TRAV")))
cat("️  PBM_STAT en STAT_TRAV zijn verwijderd.\n")
# 4. Controleer of er nog kolommen met .x of .y zijn
remaining_suffixes <- names(allgreI_filtered)[grepl("\\.x$|\\.y$", names(allgreI_filtered))]
if (length(remaining_suffixes) == 0) {
cat(" Alle kolommen met .x en .y zijn succesvol verwijderd of hernoemd!\n")
} else {
cat("Er zijn nog kolommen met .x of .y:\n")
print(remaining_suffixes)
}
# 5. Controleer de structuur van de opgeschoonde dataset
str(allgreI_filtered)
# Zet W en parking_diff om naar binaire factorvariabelen met labels "No" en "Yes"
allgreI_filtered <- allgreI_filtered %>%
mutate(
W = factor(W, levels = c(0, 1), labels = c("No", "Yes")),
parking_diff = factor(parking_diff, levels = c(0, 1), labels = c("No", "Yes"))
)
# Controleer of de omzetting correct is uitgevoerd
str(allgreI_filtered)
library(ggplot2)
library(dplyr)
# 1. Splits categorische en numerieke variabelen
cat_vars <- names(allgreI_filtered)[sapply(allgreI_filtered, is.factor)]
num_vars <- names(allgreI_filtered)[sapply(allgreI_filtered, is.numeric)]
# 2. Distributies van categorische variabelen
cat("Distributie van categorische variabelen:\n")
for (var in cat_vars) {
cat("", var, "\n")
# Frequentietabel printen
print(table(allgreI_filtered[[var]], useNA = "ifany"))
# Staafdiagram maken
plot <- ggplot(allgreI_filtered, aes_string(x = var)) +
geom_bar(fill = "steelblue", na.rm = TRUE) +
labs(title = paste("Distributie van", var), x = var, y = "Frequentie") +
theme_minimal()
print(plot)
}
# 3. Distributies van numerieke variabelen
cat("\n Distributie van numerieke variabelen:\n")
for (var in num_vars) {
cat("", var, "\n")
# Samenvatting printen
print(summary(allgreI_filtered[[var]]))
# Histogram maken
plot <- ggplot(allgreI_filtered, aes_string(x = var)) +
geom_histogram(binwidth = 1, fill = "steelblue", color = "black", na.rm = TRUE) +
labs(title = paste("Distributie van", var), x = var, y = "Frequentie") +
theme_minimal()
print(plot)
}
library(dplyr)
library(ggplot2)
# TYPE_HAB correct groeperen met grondige schoonmaak
allgreI_filtered <- allgreI_filtered %>%
mutate(
TYPE_HAB = case_when(
TYPE_HAB %in% c("1", "2") ~ "Groep 1",      # Groep 1: 1 of 2
TYPE_HAB %in% c("3", "4", "5") ~ "Groep 2",   # Groep 2: 3, 4, 5                 # Overige waarden worden NA
),
TYPE_HAB = factor(TYPE_HAB, levels = c("Groep 1", "Groep 2"))
)
# 2 OCCU1 correct groeperen
allgreI_filtered <- allgreI_filtered %>%
mutate(
OCCU1 = case_when(
OCCU1 %in% c("3", "4", "5") ~ "3-5",  # Waarden 3, 4, 5 samengevoegd
TRUE ~ as.character(OCCU1)
),
OCCU1 = factor(OCCU1)
)
# 3 Nieuwe variabele 'retrait' toevoegen
allgreI_filtered <- allgreI_filtered %>%
mutate(
retrait = ifelse(OCCU1 == "7", "Yes", "No"),
retrait = factor(retrait, levels = c("No", "Yes"))
)
# 2 nb_pers correct groeperen
allgreI_filtered <- allgreI_filtered %>%
mutate(
nb_pers = as.numeric(as.character(nb_pers)),  # Zet om naar numeriek
nb_pers = case_when(
nb_pers %in% c(1, 2) ~ as.character(nb_pers),
nb_pers %in% c(3, 4) ~ "3-4",  # Groep 3-4
nb_pers %in% c(5, 6, 7, 8) ~ "5-8",  # Groep 5-8
TRUE ~ NA_character_
),
nb_pers = factor(nb_pers, levels = c("1", "2", "3-4", "5-8"))
)
#  Controleer de aangepaste dataset
str(allgreI_filtered)
#  Bekijk de verdeling van de nieuwe groepen
cat("Verdeling van TYPE_HAB:\n")
print(table(allgreI_filtered$TYPE_HAB, useNA = "ifany"))
cat("Verdeling van OCCU1:\n")
print(table(allgreI_filtered$OCCU1, useNA = "ifany"))
cat("Verdeling van retrait:\n")
print(table(allgreI_filtered$retrait, useNA = "ifany"))
cat("Verdeling van nb_pers:\n")
print(table(allgreI_filtered$nb_pers, useNA = "ifany"))
# 5 Visualisatie van de distributies van alle variabelen
cat_vars <- names(allgreI_filtered)[sapply(allgreI_filtered, is.factor)]
num_vars <- names(allgreI_filtered)[sapply(allgreI_filtered, is.numeric)]
# Visualisatie voor categorische variabelen
for (var in cat_vars) {
cat(" Distributie van", var, ":\n")
# Frequentietabel printen
print(table(allgreI_filtered[[var]], useNA = "ifany"))
# Staafdiagram maken
plot <- ggplot(allgreI_filtered, aes_string(x = var)) +
geom_bar(fill = "steelblue", na.rm = TRUE) +
labs(title = paste("Distributie van", var), x = var, y = "Frequentie") +
theme_minimal()
print(plot)
}
# Visualisatie voor numerieke variabelen
for (var in num_vars) {
cat(" Distributie van", var, ":\n")
# Samenvatting printen
print(summary(allgreI_filtered[[var]]))
# Histogram maken
plot <- ggplot(allgreI_filtered, aes_string(x = var)) +
geom_histogram(binwidth = 1, fill = "steelblue", color = "black", na.rm = TRUE) +
labs(title = paste("Distributie van", var), x = var, y = "Frequentie") +
theme_minimal()
print(plot)
}
# 1 Nieuwe variabele 'tirgroup' aanmaken
allgreI <- allgreI %>%
mutate(tirgroup = case_when(
tir >= 101 & tir <= 114 ~ "Grenoble",
tir >= 115 & tir <= 143 ~ "Urban around Grenoble",
tir >= 201 & tir <= 205 ~ "Bièvre",
tir >= 301 & tir <= 314 ~ "Grésivaudan",
tir >= 401 & tir <= 403 ~ "Sud Grenoble",
tir >= 501 & tir <= 519 ~ "Voiron",
tir >= 601 & tir <= 603 ~ "Sud de Voiron",
tir >= 701 & tir <= 903 ~ "Montagnes",
TRUE ~ "Overig"
))
# 2 Nieuwe variabele 'fullygrouped' aanmaken
allgreI <- allgreI %>%
mutate(fullygrouped = case_when(
tirgroup %in% c("Grenoble", "Voiron") ~ "City",
tirgroup == "Montagnes" ~ "Montagnes",
TRUE ~ "Rural"
))
# Zet 'tirgroup' en 'fullygrouped' om in factors voor consistentie
allgreI <- allgreI %>%
mutate(
tirgroup = factor(tirgroup, levels = c("Grenoble", "Urban around Grenoble", "Bièvre",
"Grésivaudan", "Sud Grenoble", "Voiron",
"Sud de Voiron", "Montagnes", "Overig")),
fullygrouped = factor(fullygrouped, levels = c("City", "Montagnes", "Rural"))
)
# 3 Voeg 'fullygrouped' toe aan allgreI_filtered via een left_join
allgreI_filtered <- allgreI_filtered %>%
left_join(allgreI %>% select(id_pers, fullygrouped), by = "id_pers")
# 4 Controleer of 'fullygrouped' correct is toegevoegd
str(allgreI_filtered)
#table(allgreI_filtered$fullygrouped, useNA = "ifany")
# 5️ Opslaan van de geüpdatete dataset met 'fullygrouped'
save(allgreI_filtered, file = "allgreI_with_fullygrouped.RData")
# Save the transformed dataset to an RData file
save(allgreI_filtered, file = "allgreI_filtered.RData")
# Save the transformed dataset to an RData file
save(allgreI_filtered, file = "allgreI_clustering.RData")
load("allgreI_filtered.RData")
load("allgreI_with_W.RData")
load("allgreI_with_new_vars.RData")
library(ggplot2)     # For data visualization
library(dplyr)       # For data manipulation (e.g., mutate, rename)
library(tidyr)       # For data tidying (e.g., handling missing values)
library(skimr)
logit_model1 <- glm(immobil ~ dispovp + age_group, data = allgreI_filtered, family = binomial)
summary(logit_model1)
logit_model2 <- glm(immobil ~ W, data = allgreI_filtered, family = binomial)
summary(logit_model2)
# Lijst met alle variabelen voor aparte logistische modellen
variables <- c("dispovp", "age_group", "sexe", "cspgroup", "has_car",
"TYPE_HAB", "parking_diff", "OCCU1", "travdom", "nb_pers", "W")
# Loop door elke variabele en maak een apart logistisch model
for (var in variables) {
# Dynamische naam voor het model
model_name <- paste0("logit_model_", var)
# Formule voor het model
formula <- as.formula(paste("immobil ~", var))
# Bouw het logistisch regressiemodel
assign(model_name, glm(formula, data = allgreI_filtered, family = binomial))
# Optioneel: toon de samenvatting van elk model
cat("\n\n Samenvatting van", model_name, ":\n")
print(summary(get(model_name)))
}
# Logistisch regressiemodel
logit_model2 <- glm(immobil ~ W + dispovp + age_group, data = allgreI_filtered, family = binomial)
summary(logit_model2)
logit_model3 <- glm(immobil ~ dispovp + age_group + sexe + cspgroup+ has_car + TYPE_HAB + parking_diff + OCCU1  + nb_pers + W  , data = allgreI_filtered, family = binomial)
summary(logit_model3)
logit_model4 <- glm(immobil ~ dispovp + age_group + cspgroup+ has_car + TYPE_HAB + parking_diff + OCCU1 + nb_pers + W , data = allgreI_filtered, family = binomial)
summary(logit_model4)
logit_model5 <- glm(immobil ~ dispovp + age_group + cspgroup+ has_car + parking_diff + OCCU1 + nb_pers + W , data = allgreI_filtered, family = binomial)
summary(logit_model5)
logit_model6 <- glm(immobil ~ dispovp + age_group + cspgroup+ has_car + parking_diff + OCCU1 + W , data = allgreI_filtered, family = binomial)
summary(logit_model6)
logit_model7 <- glm(immobil ~ age_group + cspgroup+ has_car + parking_diff + OCCU1 + W , data = allgreI_filtered, family = binomial)
summary(logit_model7)
logit_model8 <- glm(immobil ~ age_group + has_car + parking_diff + OCCU1 + travdom + W , data = allgreI_filtered, family = binomial)
summary(logit_model8)
logit_model9 <- glm(immobil ~ has_car + parking_diff + OCCU1 + travdom + W , data = allgreI_filtered, family = binomial)
summary(logit_model9)
# Verwijder niet-significante OCCU1 categorieën
allgreI_filtered <- allgreI_filtered %>%
filter(!OCCU1 %in% c("3-5", "8", "9"))
logit_model9 <- glm(immobil ~ has_car + OCCU1 + W , data = allgreI_filtered, family = binomial)
summary(logit_model9)
library(caTools)
library(pROC)
library(dplyr)
set.seed(123)  # Voor reproduceerbaarheid
# 1️ Controleer ontbrekende waarden in de relevante variabelen
na_summary <- sapply(allgreI_filtered[, c("immobil", "has_car", "OCCU1", "W")], function(x) sum(is.na(x)))
print(na_summary)
# 2️ Verwijder rijen met NA's in de gebruikte variabelen (of gebruik imputatie)
clean_data <- allgreI_filtered %>%
filter(!is.na(immobil) & !is.na(has_car) & !is.na(OCCU1) & !is.na(W))
cat("Aantal observaties na opschonen:", nrow(clean_data), "\n")
# 3️ 80% Train - 20% Test split op de opgeschoonde dataset
split <- sample.split(clean_data$immobil, SplitRatio = 0.8)
train_data <- subset(clean_data, split == TRUE)
test_data <- subset(clean_data, split == FALSE)
# 4️ Zorg dat de levels van OCCU1, immobil en andere factoren gelijk zijn
train_data$OCCU1 <- factor(train_data$OCCU1, levels = levels(clean_data$OCCU1))
test_data$OCCU1 <- factor(test_data$OCCU1, levels = levels(train_data$OCCU1))
train_data$immobil <- factor(train_data$immobil, levels = c("No", "Yes"))
test_data$immobil <- factor(test_data$immobil, levels = c("No", "Yes"))
# 5️ Model trainen met logit_model9 specificatie
logit_model9 <- glm(immobil ~ has_car + OCCU1 + W,
data = train_data,
family = binomial)
# Samenvatting van het model
summary(logit_model9)
# Odds Ratios berekenen
odds_ratios <- exp(coef(logit_model9))
#  95% Betrouwbaarheidsintervallen voor de Odds Ratios
conf_intervals <- exp(confint(logit_model9))
# Gecombineerde tabel van OR en CI
or_table <- cbind(Odds_Ratio = odds_ratios)
print(round(or_table, 3))
# 6️ Kansvoorspellingen maken
predictions_prob <- predict(logit_model9, newdata = test_data, type = "response")
# 7️ Omzetten naar classificatie met drempelwaarde van 0.5
predictions_class <- ifelse(predictions_prob > 0.5, "Yes", "No")
# 8️ Zet voorspellingen om naar factor met dezelfde levels als 'immobil'
predictions_class <- factor(predictions_class, levels = levels(test_data$immobil))
# 9 Confusion Matrix
conf_matrix <- table(Predicted = predictions_class, Actual = test_data$immobil)
print(conf_matrix)
# 10 Bereken nauwkeurigheid (accuracy)
accuracy <- mean(predictions_class == test_data$immobil)
cat("Model Accuracy:", round(accuracy * 100, 2), "%\n")
# ROC-curve en AUC-waarde berekenen
roc_curve <- roc(test_data$immobil, predictions_prob)
# Plot de ROC-curve
plot(roc_curve, col = "blue", main = "ROC Curve - logit_model9")
abline(a = 0, b = 1, lty = 2, col = "red")
# Bereken de AUC (Area Under the Curve)
auc_value <- auc(roc_curve)
cat("AUC-waarde:", round(auc_value, 3), "\n")
# 1 Controleer ontbrekende waarden in de relevante variabelen
na_summary <- sapply(allgreI_filtered[, c("immobil", "has_car", "OCCU1", "W", "age_group", "dispovp")], function(x) sum(is.na(x)))
print(na_summary)
# 2️ Verwijder rijen met NA's
clean_data <- allgreI_filtered %>%
filter(!is.na(immobil) & !is.na(has_car) & !is.na(OCCU1) & !is.na(W) & !is.na(age_group) & !is.na(dispovp))
cat("Aantal observaties na opschonen:", nrow(clean_data), "\n")
# 3️ 80% Train - 20% Test split
split <- sample.split(clean_data$immobil, SplitRatio = 0.8)
train_data <- subset(clean_data, split == TRUE)
test_data <- subset(clean_data, split == FALSE)
# 4️ Zorg dat de levels van alle factoren gelijk zijn
factor_vars <- c("OCCU1", "age_group", "immobil")
for (var in factor_vars) {
train_data[[var]] <- factor(train_data[[var]], levels = levels(clean_data[[var]]))
test_data[[var]]  <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# 5️ Model trainen met age_group, dispovp en W
logit_model_new <- glm(immobil ~ age_group + dispovp + W,
data = train_data,
family = binomial)
summary(logit_model_new)
#  Odds Ratios berekenen
odds_ratios <- exp(coef(logit_model2))
#  95% Betrouwbaarheidsintervallen voor de Odds Ratios
conf_intervals <- exp(confint(logit_model2))
#  Gecombineerde tabel van OR en CI
or_table <- cbind(Odds_Ratio = odds_ratios)
print(round(or_table, 3))
# 6️ Kansvoorspellingen maken
predictions_prob_new <- predict(logit_model_new, newdata = test_data, type = "response")
# 7️ Classificatie met drempelwaarde 0.4
predictions_class_new <- ifelse(predictions_prob_new > 0.45, "Yes", "No")
predictions_class_new <- factor(predictions_class_new, levels = levels(test_data$immobil))
# 8️ Confusion Matrix
conf_matrix_new <- table(Predicted = predictions_class_new, Actual = test_data$immobil)
print(conf_matrix_new)
# 9️ Nauwkeurigheid
accuracy_new <- mean(predictions_class_new == test_data$immobil)
cat("Model Accuracy:", round(accuracy_new * 100, 2), "%\n")
# 10 ROC-curve en AUC
roc_curve_new <- roc(test_data$immobil, predictions_prob_new)
plot(roc_curve_new, col = "green", main = "ROC Curve - New Model")
abline(a = 0, b = 1, lty = 2, col = "red")
auc_value_new <- auc(roc_curve_new)
cat("AUC-waarde:", round(auc_value_new, 3), "\n")
library(caret)  # Voor het berekenen van F1, Precision en Recall
# Samenvatting voor logit_model_new
# Confusion matrix voor het logit model
conf_matrix_logit_model <- confusionMatrix(predictions_class_new, test_data$immobil, positive = "Yes")
#  Extractie van de evaluatiemetrics voor het logit model
accuracy_logit_model <- conf_matrix_logit_model$overall['Accuracy']
precision_logit_model <- conf_matrix_logit_model$byClass['Precision']
recall_logit_model <- conf_matrix_logit_model$byClass['Recall']
f1_logit_model <- conf_matrix_logit_model$byClass['F1']
#  Samenvattende tabel maken
summary_table <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1-Score"),
Logit_Model = c(round(accuracy_logit_model, 3), round(precision_logit_model, 3), round(recall_logit_model, 3), round(f1_logit_model, 3))
)
# Duidelijke weergave van de resultaten
# cat("\nEvaluatiemetrics Samenvatting - Logit Model:\n")
print(summary_table)
knitr::opts_chunk$set(echo = TRUE)
library(skimr)
library(dplyr)
library(randomForest)
library(rpart)  # Für den Entscheidungsbaum
library(rpart.plot)  # Für die Visualisierung des Entscheidungsbaums
library(caret)
# Load the necessary dataset
load("allgreI.RData")
#load("C:/SAProject/Files_OK_SABD_Prject/allgreM.RData")
#load("C:/SAProject/Files_OK_SABD_Prject/allgreD.RData")
load("allgreI_with_W.RData")
# Zufällige Teilung von allgreI in Trainings- und Testdaten (70%-30%)
set.seed(123) # Für Reproduzierbarkeit
# Erzeuge zufällige Indizes für die Trainingsdaten von allgreI
train_indices <- sample(1:nrow(allgreI), size = 0.7 * nrow(allgreI))
# Teile allgreI auf
allgreI_filtered_train <- allgreI_filtered[train_indices, ]
allgreI_filtered_test <- allgreI_filtered[-train_indices, ]
# Bestätige die Aufteilung
dim(allgreI_filtered_train) # Zeigt die Dimensionen der Trainingsdaten
dim(allgreI_filtered_test)  # Zeigt die Dimensionen der Testdaten
class(allgreI_filtered_test$immobil)
class(allgreI_filtered_train$immobil)
model_tree10 <- rpart(
immobil ~ age_group + dispovp + W,  # Drei erklärende Variablen
data = allgreI_filtered_train,      # Trainingsdatensatz
method = "class"          # Klassifikationsbaum
)
# Zeige die Struktur des Baumes an
print(model_tree10)
# Zusammenfassung des Entscheidungsbaums
summary(model_tree10)
# Visualisierung des Entscheidungsbaums
library(rpart.plot)
rpart.plot(model_tree10, type = 3, extra = 104, fallen.leaves = TRUE)
# Vorhersage auf den Testdaten
pred_tree10 <- predict(model_tree10, newdata = allgreI_filtered_test, type = "class")
# Evaluierung der Modellgüte mit einer Konfusionsmatrix
conf_matrix_tree <- table(Predicted = pred_tree10, Actual = allgreI_filtered_test$immobil)
conf_matrix_tree
#Test
confusionMatrix(pred_tree10, allgreI_filtered_test$immobil)
# Berechne die Genauigkeit (Accuracy)
accuracy_tree <- sum(diag(conf_matrix_tree)) / sum(conf_matrix_tree)
cat("Accuracy:", accuracy_tree, "\n")
# Berechne Precision, Recall und F1-Score aus der Konfusionsmatrix
# Extrahiere die Werte aus der Konfusionsmatrix
TP <- conf_matrix_tree[2, 2]  # True Positives (richtig als 1 klassifizierte 1)
FP <- conf_matrix_tree[1, 2]  # False Positives (fälschlich als 1 klassifizierte 0)
TN <- conf_matrix_tree[1, 1]  # True Negatives (richtig als 0 klassifizierte 0)
FN <- conf_matrix_tree[2, 1]  # False Negatives (fälschlich als 0 klassifizierte 1)
# Berechne Precision (Präzision)
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")
# Berechne Recall (Sensitivität)
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")
# Berechne F1-Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1-Score:", f1_score, "\n")
# Überprüfen, ob die Variable 'target_child' existiert
if (!exists("target_child")) {
message("Die Datei wird eigenständig ausgeführt.")
knitr::opts_chunk$set(echo = TRUE, include = TRUE)
} else {
message("Die Datei wird eingebunden.")
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
}
# Ausgabe der aktuellen Chunk-Optionen
message("Aktuelle Einstellungen für echo: ", knitr::opts_chunk$get("echo"))
message("Aktuelle Einstellungen für include: ", knitr::opts_chunk$get("include"))
# Überprüfen, ob die Variable 'target_child' existiert
if (!exists("target_child")) {
message("Die Datei wird eigenständig ausgeführt.")
knitr::opts_chunk$set(echo = TRUE, include = TRUE)
} else {
message("Die Datei wird eingebunden.")
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
}
# Ausgabe der aktuellen Chunk-Optionen
message("Aktuelle Einstellungen für echo: ", knitr::opts_chunk$get("echo"))
message("Aktuelle Einstellungen für include: ", knitr::opts_chunk$get("include"))
# Bedingung: Wenn die Datei eigenständig ausgeführt wird, zeige alles an
if (!exists("target_child")) {
message("child.Rmd wird eigenständig ausgeführt.")
knitr::opts_chunk$set(echo = TRUE, include = TRUE)
} else {
# Wenn die Datei eingebunden wird, unterdrücke die Ausgabe
message("child.Rmd wird durch die Hauptdatei eingebunden.")
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
}
# Bedingung: Wenn die Datei eigenständig ausgeführt wird, zeige alles an
if (!exists("target_child")) {
message("child.Rmd wird eigenständig ausgeführt.")
knitr::opts_chunk$set(echo = TRUE, include = TRUE)
} else {
# Wenn die Datei eingebunden wird, unterdrücke die Ausgabe
message("child.Rmd wird durch die Hauptdatei eingebunden.")
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
}
# Beispiel-Code
print("Dies ist eine Ausgabe aus der eingebundenen Datei.")
# Variable setzen, um die eingebundene Datei zu steuern
target_child <- "childTest.Rmd"
# Die eingebundene Datei wird hier eingefügt.
